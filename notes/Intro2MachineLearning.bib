
@book{vaart_asymptotic_1998,
	address = {Cambridge, UK ; New York, NY, USA},
	title = {Asymptotic {Statistics}},
	isbn = {9780521496032},
	abstract = {Here is a practical and mathematically rigorous introduction to the field of asymptotic statistics. In addition to most of the standard topics of an asymptotics course--likelihood inference, M-estimation, the theory of asymptotic efficiency, U-statistics, and rank procedures--the book also presents recent research topics such as semiparametric models, the bootstrap, and empirical processes and their applications. The topics are organized from the central idea of approximation by limit experiments, one of the book's unifying themes that mainly entails the local approximation of the classical i.i.d. set up with smooth parameters by location experiments involving a single, normally distributed observation.},
	language = {English},
	publisher = {Cambridge University Press},
	author = {Vaart, A. W. van der},
	month = oct,
	year = {1998},
	file = {Asymptotic Statistics [van der Vaart].pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/URPF9ZVW/Asymptotic Statistics [van der Vaart].pdf:application/pdf}
}

@book{hastie_elements_2003,
	title = {The {Elements} of {Statistical} {Learning}},
	isbn = {0387952845},
	abstract = {During the past decade there has been an explosion in computation and information technology. With it has come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics.

Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a valuable resource for statisticians and anyone interested in data mining in science or industry.

The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting--the first comprehensive treatment of this topic in any book.

Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie wrote much of the statistical modeling software in S-PLUS and invented principal curves and surfaces. Tibshirani proposed the Lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, and projection pursuit.

FROM THE REVIEWS:

TECHNOMETRICS "[This] is a vast and complex book. Generally, it concentrates on explaining why and how the methods work, rather than how to use them. Examples and especially the visualizations are principle features...As a source for the methods of statistical learning...it will probably be a long time before there is a competitor to this book."},
	urldate = {2014-12-11},
	publisher = {Springer},
	author = {Hastie, T and Tibshirani, R and Friedman, JH},
	month = jul,
	year = {2003},
	keywords = {machine-learning, statistic}
}

@book{james_introduction_2013,
	address = {New York},
	edition = {1st ed. 2013. Corr. 4th printing 2014 edition},
	title = {An {Introduction} to {Statistical} {Learning}: with {Applications} in {R}},
	isbn = {9781461471370},
	shorttitle = {An {Introduction} to {Statistical} {Learning}},
	abstract = {An Introduction to Statistical Learning provides an accessible overview of the field of statistical learning, an essential toolset for making sense of the vast and complex data sets that have emerged in fields ranging from biology to finance to marketing to astrophysics in the past twenty years. This book presents some of the most important modeling and prediction techniques, along with relevant applications. Topics include linear regression, classification, resampling methods, shrinkage approaches, tree-based methods, support vector machines, clustering, and more. Color graphics and real-world examples are used to illustrate the methods presented. Since the goal of this textbook is to facilitate the use of these statistical learning techniques by practitioners in science, industry, and other fields, each chapter contains a tutorial on implementing the analyses and methods presented in R, an extremely popular open source statistical software platform.Two of the authors co-wrote The Elements of Statistical Learning (Hastie, Tibshirani and Friedman, 2nd edition 2009), a popular reference book for statistics and machine learning researchers. An Introduction to Statistical Learning covers many of the same topics, but at a level accessible to a much broader audience. This book is targeted at statisticians and non-statisticians alike who wish to use cutting-edge statistical learning techniques to analyze their data. The text assumes only a previous course in linear regression and no knowledge of matrix algebra.},
	language = {English},
	publisher = {Springer},
	author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
	month = aug,
	year = {2013}
}

@book{shalev-shwartz_understanding_2014,
	address = {New York, NY},
	title = {Understanding {Machine} {Learning}: {From} {Theory} to {Algorithms}},
	isbn = {9781107057135},
	shorttitle = {Understanding {Machine} {Learning}},
	abstract = {Machine learning is one of the fastest growing areas of computer science, with far-reaching applications. The aim of this textbook is to introduce machine learning, and the algorithmic paradigms it offers, in a principled way. The book provides an extensive theoretical account of the fundamental ideas underlying machine learning and the mathematical derivations that transform these principles into practical algorithms. Following a presentation of the basics of the field, the book covers a wide array of central topics that have not been addressed by previous textbooks. These include a discussion of the computational complexity of learning and the concepts of convexity and stability; important algorithmic paradigms including stochastic gradient descent, neural networks, and structured output learning; and emerging theoretical concepts such as the PAC-Bayes approach and compression-based bounds. Designed for an advanced undergraduate or beginning graduate course, the text makes the fundamentals and algorithms of machine learning accessible to students and non-expert readers in statistics, computer science, mathematics, and engineering.},
	language = {English},
	publisher = {Cambridge University Press},
	author = {Shalev-Shwartz, Shai and Ben-David, Shai},
	month = may,
	year = {2014}
}

@book{wasserman_all_2004,
	address = {New York},
	title = {All of statistics: a concise course in statistical inference},
	isbn = {0387402721  9780387402727},
	shorttitle = {All of statistics},
	abstract = {"This book is for people who want to learn probability and statistics quickly. It brings together many of the main ideas in modern statistics in one place. The book is suitable for students and researchers in statistics, computer science, data mining, and machine learning." "This book covers a much wider range of topics than a typical introductory text on mathematical statistics. It includes modern topics like nonparametric curve estimation, bootstrapping, and classification, topics that are usually relegated to follow-up courses. The reader is assumed to know calculus and a little linear algebra. No previous knowledge of probability and statistics is required. The text can be used at the advanced undergraduate and graduate levels."--BOOK JACKET.},
	language = {English},
	publisher = {Springer},
	author = {Wasserman, Larry},
	year = {2004},
	file = {All Of Statistics [Wasserman].pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/R7TU8M27/All Of Statistics [Wasserman].pdf:application/pdf}
}