\documentclass[12pt,a4paper]{article}



\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{marginnote}
\usepackage{natbib}





\author{Jonathan Rosenblatt}
\title{Class Notes (experimental)}




\theoremstyle{plain}
\newtheorem{thm}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{prop}{Proposition}

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}
\newtheorem{example}{Example}




\newcommand{\expect}[1]{E[#1]}
\newcommand{\expectn}[1]{\mathbb{E}[#1]}
\newcommand{\gauss}[1]{\mathcal{N}(#1)}
\newcommand{\cdf}[2]{F_{#1}(#2)}
\newcommand{\cdfn}[2]{\mathbb{F}_{#1}(#2)}
\newcommand{\icdf}[2]{F^{-1}_{#1}(#2)}
\newcommand{\icdfn}[2]{\mathbb{F}^{-1}_{#1}(#2)}
\newcommand{\norm}[1]{\Vert #1 \Vert}
\newcommand{\lik}[1]{\mathcal{L}(#1)}
\newcommand{\loglik}[1]{L(#1)}
\newcommand{\loss}[1]{l(#1)}
\newcommand{\risk}[1]{R(#1)}
\newcommand{\riskn}[1]{\mathbb{R}(#1)}
\newcommand{\deriv}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\argmin}[2]{argmin_{#1}\left\{ #2 \right\}}

\begin{document}

\maketitle


\section{Estimation}
\label{sec:estimation} 
In this section, we present several estimation principeles. 
Their properties are not discussed, as the section is merely a reminder and a preparation for Section~\ref{sec:learning}.
These concepts and examples can be found in many introductory books to statistics. I particularly recommend \citep{wasserman_all_2004}.

\subsection{Moment matching}
\label{sec:moment_matching}

The fundamental idea: match empirical moments to theoretical. I.e., estimate
$$ \expect{g(X)}   $$
by 
$$ \expectn{g(X)}   $$
where $\expectn{g(X)}:=\frac{1}{n}  \sum_i g(X_i)$, is the empirical mean.

\begin{example}[Exponential Rate]

Estimate $\lambda$ in $X_i \sim exp(\lambda)$, $i=1,\dots,n$, i.i.d.
$\expect{X}=1/\lambda$.
$\Rightarrow \hat{\lambda}=1/\expectn{X}$ 

\end{example}


\begin{example}[Linear Regression]

Estimate $\beta$ in $Y \sim \gauss{X\beta,\sigma^2 I}$, a $p$ dimensional random vector.
$\expect{Y}=X\beta$ and $\expectn{Y}=y$.
Clearly, moment mathing won't work because no $\beta$ satistifes $X\beta=Y$.
A technical workaround:
Since $\beta$ is $p$ dimensional, I need to find some $g(Y): \mathbb{R}^n \mapsto \mathbb{R}^p$.
Well, $g(Y):=XY$ is such a mapping. I will use it, even though my technical justification is currently unsatisfactory. We thus have:
$\expect{X'Y}=X'X\beta$ which I match to $\expectn{X'Y}=X'y$:
$$
  X'X \beta = X' y \Rightarrow \hat{\beta}=(X'X)^{-1} X'y.
$$

\end{example}


\subsection{Quantile matching}
\label{sec:quantiles}
The fundamental idea: match empirical quantiles to theoretical. 
Denoting by $\cdf{X}{t}$ the CDF of $X$, then $\icdf{X}{\alpha}$ is the $\alpha$ quantile of $X$.
Also denoting by $\cdfn{X}{t}$ the Empirical CDF of $X_1,\dots, X_n$, then $\icdfn{X}{\alpha}$ is the $\alpha$ quantile of $X_1,\dots, X_n$.
The quantile matching method thus implies estimating
$$ \icdf{X}{\alpha}   $$
by 
$$ \icdfn{X}{\alpha}  . $$

\begin{example}[Exponential rate]
Estimate $\lambda$ in $X_i \sim exp(\lambda)$, $i=1,\dots,n$, i.i.d.
\begin{align*}
	  \cdf{X}{t} =& 1-\exp(-\lambda t) = \alpha \Rightarrow \\
  \icdf{X}{\alpha} =& \frac{-\log(1-\alpha)}{\lambda} \Rightarrow \\
  \icdf{X}{0.5} =& \frac{-\log(0.5)}{\lambda} \Rightarrow \\
  \hat{\lambda} =& \frac{-\log(0.5)}{\icdfn{X}{0.5}}.
\end{align*}

\end{example}


\subsection{Maximum Likelihood}
\label{sec:ml}

The fundamental idea is that if the data generating proces (i.e., the \emph{sampling distribution}) can be assumed, then the observations are probably some high probability instance of this process, and not a low probability event:
Let $X_1,\dots,X_n \sim P_\theta$, with density (or probability) $p_\theta(X_1,\dots,X_n)$.
Denote the likelihood, as a function of $\theta$: $\lik{\theta}: p_\theta(X_1,\dots,X_n)$.
Then $\hat{\theta}_{ML}:= argmax_{\theta}\{ \lik{\theta} \}$.

\begin{example}[Exponential rate]

Estimate $\lambda$ in $X_i \sim exp(\lambda)$, $i=1,\dots,n$, i.i.d.
Using the exponential PDF and the i.i.d. assumption
$$ \lik{\lambda} = \lambda^n \exp(-\lambda \sum_i X_i). $$
Using a monotone mapping such as the log, does not change the $argmax$. 
Denoting $\loglik{\theta}:=\log(\lik{\theta})$, we have
$$ \loglik{\lambda} = n \log(\lambda) -\lambda \sum_i X_i. $$
By differentiating and equating $0$, we get $\hat{\lambda}_{ML}=1/\expectn{X}$.

\end{example}

\begin{example}[Discrete time Markov Chain]

Estimate the transition probabilities,  $p_1$ and $p_2$ in a two state, $\{0,1\}$, discrete time, Markov chain where:
$P(X_{t+1}=1|X_{t}=0)=p_1$ and $P(X_{t+1}=1|X_{t}=1)=p_2$.
The likelihood:
$$
  \lik{p_1,p_2}=P(X_1,\dots,X_n;p_1,p_2)=\prod_{t=0}^T P(X_{t+1}=x_{t+1}|X_{t}=x_t).
$$
We denote $n_{ij}$ the number of observed transitions from $i$ to $j$ and get that $\hat{p}_1=\frac{n_{01}}{n_{01}+n_{00}}$, and that $\hat{p}_2=\frac{n_{11}}{n_{11}+n_{10}}$.

\begin{remark}
Well, this is a rather artificial example, as because of the Markov property, and the stationarity of the process, we only need to look at transition events, themselves Brenoulli distributed. 
This example does show, however, the power of the ML method to deal with non i.i.d. samples. As does the next example.
\end{remark}
\end{example}

\begin{example}[Brownian motion with drift]
Estimate the drift parameter $a$,  in a discrete time Gaussian process where:
$X_{t+1}=X_t+\varepsilon; \varepsilon \sim \gauss{0,\sigma^2} \Rightarrow X_{t+1}|X_t \sim \gauss{a X_t,\sigma^2}$.

We start with the conditional density at time $t+1$:
$$
  p_{X_{t+1}|X_t=x_t}(x_{t+1}) = 
  (2 \pi \sigma^2)^{-1/2} \exp \left( 
    -\frac{1}{2 \sigma^2}(x_{t+1}-a x_t)^2 
  \right).
$$
Moving to the likelihood:
$$
  \lik{a} = 
  (2 \pi \sigma^2)^{-T/2} \exp \left(
    -\frac{1}{2 \sigma^2}\sum_{t=1}^T (x_{t+1}-a x_t)^2 
  \right).
$$
Differentiating with respect to $a$ and equating $0$ we get $\hat{a}_{ML}=\frac{\sum x_{t+1}x_{t}}{\sum x_t^2}$.

We again see the power of the ML device.
Could we have arrive to this estimator by intuiton alone? Hmmmm... maybe. 
See that $Cov[X_{t+1},X_t] = a \; Var[X_t] \Rightarrow a=\frac{Cov[X_{t+1},X_t]}{Var[X_t]}$.
So $a$ can also be derived using the moment matching method which is probably more intuitive.

\end{example}

\begin{example}[Linear Regression]

Estimate $\beta$ in $Y \sim \gauss{X\beta,\sigma^2 I}$, a $p$ dimensional random vector.
Recalling the multivariate Gaussian PDF:
$$
  p_{\mu,\Sigma}(y) = 
  (2 \pi)^{-n/2} |\Sigma|^{-1/2} \exp\left(
    -\frac{1}{2} (y-\mu)' \Sigma^{-1} (y-\mu)
  \right)
$$
So in the regression setup:
$$
  \lik{\beta}= 
  p_{\beta,\sigma^2}(y) = 
  (2 \pi)^{-n/2} |\sigma^2 I|^{-1/2} \exp\left(
    -\frac{1}{2 \sigma^2} \norm{y-X\beta}^2
  \right)
$$

\end{example}


\subsection{M-Estimation and Empirical Risk Minimization}
\label{sec:m_estimation}

M-Estimation, know as Empirical Risk Minimizaton (ERM) in the machine learning literature, is a very wide framework which stems from statistical desicion theory.
The underlying idea is that each realization of $X$ incurs some loss, and we seek to find a "policy", in this case a parameter, $\theta^*$ that minimizes the average loss.
In the econometric literature, we dot not incur a loss, but rather a utility, we thus seek a policy that maximizes the average utility.

Define a loss function $\loss{X;\theta}$, and a risk function, being the expected loss, 
$\risk{\theta}:=\expect{\loss{X;\theta}}$. Then 
\begin{align}
\label{eq:risk_min}
 \theta^*:= \argmin{\theta}{\risk{\theta}}.
\end{align}



As we do not know the distribution of $X$, we cannot solve Eq.(\ref{eq:risk_min}), so we minimize the \emph{empirical} risk. 
Define the empirical risk as $\riskn{\theta}:=\expectn{\loss{X;\theta}}$, then 
\begin{align}
\label{eq:empirical_risk_min}
 \hat{\theta}:= \argmin{\theta}{\riskn{\theta}}.
\end{align}





\begin{example}[Squared Loss]
Let $\loss{X;\theta}=(X-\theta)^2$. Then 
$
	\risk{\theta} = 
	\expect{(X-\theta)^2} = 
	(\expect{X}-\theta)^2 + Var[X]. 
$
Clearly $Var[X]$ does not depend on $\theta$  so that $\risk{\theta}$ is minimized by $\theta^*=\expect{X}$.
\textbf{We thus say that the expectation of a random variable is the minimizer of the squared loss.}

How do we estimate the population expectation? Well a natural estimator is the empirical mean, which is also the minimizer of the empirical risk $\riskn{X}$. The proof is immediate by differentiating. 
\end{example}



\begin{example}[Least Squares Regression]
Define the loss $\loss{Y,X;\beta}:=\frac{1}{2}(Y-X\beta)^2$.
Computing the risk, $\expect{\norm{Y-X\beta}^2}$ will require dealing with the $X$'s by either assuming the \textbf{Generative Model}\footnote{A Generative Model is a supervised learning problem where the we use the assumed distribution of the $X$s and not only $Y|X$. The latter are know as Discriminative Models.}, as expectation is taken over $X$ and $Y$. 
We don't really care about that right now. 
We merely want to see that the empirical risk minimizer, is actually the classical OLS Regression. And well, it is, by definition...
\begin{align*}
	\riskn{\beta}=\sum_{i=1}^n 	\frac{1}{2}(y-x_i\beta)^2 = \frac{1}{2}\norm{y-x\beta}^2.
\end{align*}
Minimization is easiest with vector derivatives, but I will stick to regular derivatives:
\begin{align*}
	\deriv{\riskn{\beta}}{{\beta_j}} = \sum_i \left[ (y_i-\sum_{j=1}^p x_{ij}\beta_j)(-x_{ij}) \right]
\end{align*}
Equating $0$ yields $\hat{\beta_j}=\frac{\sum_i y_i x_{ij}}{\sum_i x_{ij}^2}$.
Solving for all $j$'s and putting in matrix notation we get
\begin{align}
	\hat{\beta}_{OLS}=(X'X)^{-1} X'y.
\end{align}


\end{example}


\subsection{Notes}
\paragraph{Maximum Likelhood} 
If we set the loss function to be the negative log likelihood of the (true) sampling distribution, we see that maximum likelihood estimators in independent samples are actually a certain type of M-estimators.


\section{From Estimation to Supervised Learning}
\label{sec:learning}
This section draws from \cite{hastie_elements_2003} and \cite{shalev-shwartz_understanding_2014}


\subsection{Empirical Risk Minimization (ERM) and Inductive Bias}
In Supervised Learning problems where we want to extract the relation $y=f(x)$ between attributes $x$ and some outcome $y$.
In particular, we don't need to explain the causal process relating the two, so there is no need to commit to a sampling distribution. The implied M-Estimation problem is thus
\begin{align}
	\hat{f}(x) = \argmin{f}{\sum_i \loss{y_i-f(x_i)}}.
\end{align}
Alas, there are clearly infinitely many $f$ for which $\riskn{f}=0$, in particular, all those where $f(x_i)=y_i$.
All these $f$s feel like very bad predictors (we will revisit this matter in Section~\ref{sec:desicion_theory}).


\subsection{Linear Regression (OLS)}

\subsection{Ridge Regression}

\subsection{Logistic Regression}

\subsection{LASSO}

\subsection{Linear SVM }

\subsection{Generalized Additive Models (GAMs)}

\subsection{Neural Nets (NNETs)}

\subsection{Classification and Regression Trees (CARTs)}





\section{Unsupervised Learning}
\label{sec:unsupervised}

\section{Statistical Decision Theory}
\label{sec:desicion_theory}

\section{Dimensionality Reduction}
\label{sec:dim_reduce}

\section{Latent Space Models}
\label{sec:latent_space}






\bibliographystyle{abbrvnat}
\bibliography{Intro2MachineLearning}


\end{document}