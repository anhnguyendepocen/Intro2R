\documentclass[12pt,a4paper]{article}



\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{marginnote}





\author{Jonathan Rosenblatt}
\title{Class Notes (experimental)}




\theoremstyle{plain}
\newtheorem{thm}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{prop}{Proposition}

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}
\newtheorem{example}{Example}




\newcommand{\expect}[1]{E[#1]}
\newcommand{\expectn}[1]{\mathbb{E}[#1]}
\newcommand{\gauss}[1]{\mathcal{N}(#1)}
\newcommand{\cdf}[2]{F_{#1}(#2)}
\newcommand{\cdfn}[2]{\mathbb{F}_{#1}(#2)}
\newcommand{\icdf}[2]{F^{-1}_{#1}(#2)}
\newcommand{\icdfn}[2]{\mathbb{F}^{-1}_{#1}(#2)}
\newcommand{\norm}[1]{\Vert #1 \Vert}
\newcommand{\lik}[1]{\mathcal{L}(#1)}
\newcommand{\loglik}[1]{L(#1)}
\newcommand{\loss}[1]{l(#1)}
\newcommand{\risk}[1]{R(#1)}



\begin{document}

\maketitle


\section{Estimation}
\label{sec:estimation} 
In this section, we present several estimation principeles. 
Their properties are not discussed, as the section is merely a reminder and a preparation for Section~\ref{sec:learning}.

\subsection{Moment matching}
\label{sec:moment_matching}

The fundamental idea: match empirical moments to theoretical. I.e., estimate
$$ \expect{g(X)}   $$
by 
$$ \expectn{g(X)}   $$
where $\expectn{g(X)}:=\frac{1}{n}  \sum_i g(X_i)$, is the empirical mean.

\begin{example}[Exponential Rate]

Estimate $\lambda$ in $X_i \sim exp(\lambda)$, $i=1,\dots,n$, i.i.d.
$\expect{X}=1/\lambda$.
$\Rightarrow \hat{\lambda}=1/\expectn{X}$ 

\end{example}


\begin{example}[Linear Regression]

Estimate $\beta$ in $Y \sim \gauss{X\beta,\sigma^2 I}$, a $p$ dimensional random vector.
$\expect{Y}=X\beta$ and $\expectn{Y}=y$.
Clearly, moment mathing won't work because no $\beta$ satistifes $X\beta=Y$.
A technical workaround:
Since $\beta$ is $p$ dimensional, I need to find some $g(Y): \mathbb{R}^n \mapsto \mathbb{R}^p$.
Well, $g(Y):=XY$ is such a mapping. I will use it, even though my technical justification is currently unsatisfactory. We thus have:
$\expect{X'Y}=X'X\beta$ which I match to $\expectn{X'Y}=X'y$:
$$
  X'X \beta = X' y \Rightarrow \hat{\beta}=(X'X)^{-1} X'y.
$$

\end{example}


\subsection{Quantile matching}
\label{sec:quantiles}
The fundamental idea: match empirical quantiles to theoretical. 
Denoting by $\cdf{X}{t}$ the CDF of $X$, then $\icdf{X}{\alpha}$ is the $\alpha$ quantile of $X$.
Also denoting by $\cdfn{X}{t}$ the Empirical CDF of $X_1,\dots, X_n$, then $\icdfn{X}{\alpha}$ is the $\alpha$ quantile of $X_1,\dots, X_n$.
The quantile matching method thus implies estimating
$$ \icdf{X}{\alpha}   $$
by 
$$ \icdfn{X}{\alpha}  . $$

\begin{example}[Exponential rate]
Estimate $\lambda$ in $X_i \sim exp(\lambda)$, $i=1,\dots,n$, i.i.d.
\begin{align*}
	  \cdf{X}{t} =& 1-\exp(-\lambda t) = \alpha \Rightarrow \\
  \icdf{X}{\alpha} =& \frac{-\log(1-\alpha)}{\lambda} \Rightarrow \\
  \icdf{X}{0.5} =& \frac{-\log(0.5)}{\lambda} \Rightarrow \\
  \hat{\lambda} =& \frac{-\log(0.5)}{\icdfn{X}{0.5}}.
\end{align*}

\end{example}


\subsection{Maximum Likelihood}
\label{sec:ml}

The fundamental idea is that if the data generating proces (i.e., the \emph{sampling distribution}) can be assumed, then the observations are probably some high probability instance of this process, and not a low probability event:
Let $X_1,\dots,X_n \sim P_\theta$, with density (or probability) $p_\theta(X_1,\dots,X_n)$.
Denote the likelihood, as a function of $\theta$: $\lik{\theta}: p_\theta(X_1,\dots,X_n)$.
Then $\hat{\theta}_{ML}:= argmax_{\theta}\{ \lik{\theta} \}$.

\begin{example}[Exponential rate]

Estimate $\lambda$ in $X_i \sim exp(\lambda)$, $i=1,\dots,n$, i.i.d.
Using the exponential PDF and the i.i.d. assumption
$$ \lik{\lambda} = \lambda^n \exp(-\lambda \sum_i X_i). $$
Using a monotone mapping such as the log, does not change the $argmax$. 
Denoting $\loglik{\theta}:=\log(\lik{\theta})$, we have
$$ \loglik{\lambda} = n \log(\lambda) -\lambda \sum_i X_i. $$
By differentiating and equating $0$, we get $\hat{\lambda}_{ML}=1/\expectn{X}$.

\end{example}

\begin{example}[Discrete time Markov Chain]

Estimate the transition probabilities,  $p_1$ and $p_2$ in a two state, $\{0,1\}$, discrete time, Markov chain where:
$P(X_{t+1}=1|X_{t}=0)=p_1$ and $P(X_{t+1}=1|X_{t}=1)=p_2$.
The likelihood:
$$
  \lik{p_1,p_2}=P(X_1,\dots,X_n;p_1,p_2)=\prod_{t=0}^T P(X_{t+1}=x_{t+1}|X_{t}=x_t).
$$
We denote $n_{ij}$ the number of observed transitions from $i$ to $j$ and get that $\hat{p}_1=\frac{n_{01}}{n_{01}+n_{00}}$, and that $\hat{p}_2=\frac{n_{11}}{n_{11}+n_{10}}$.

\begin{remark}
Well, this is a rather artificial example, as because of the Markov property, and the stationarity of the process, we only need to look at transition events, themselves Brenoulli distributed. 
This example does show, however, the power of the ML method to deal with non i.i.d. samples. As does the next example.
\end{remark}
\end{example}

\begin{example}[Brownian motion with drift]
Estimate the drift parameter $a$,  in a discrete time Gaussian process where:
$X_{t+1}=X_t+\varepsilon; \varepsilon \sim \gauss{0,\sigma^2} \Rightarrow X_{t+1}|X_t \sim \gauss{a X_t,\sigma^2}$.

We start with the conditional density at time $t+1$:
$$
  p_{X_{t+1}|X_t=x_t}(x_{t+1}) = 
  (2 \pi \sigma^2)^{-1/2} \exp \left( 
    -\frac{1}{2 \sigma^2}(x_{t+1}-a x_t)^2 
  \right).
$$
Moving to the likelihood:
$$
  \lik{a} = 
  (2 \pi \sigma^2)^{-T/2} \exp \left(
    -\frac{1}{2 \sigma^2}\sum_{t=1}^T (x_{t+1}-a x_t)^2 
  \right).
$$
Differentiating with respect to $a$ and equating $0$ we get $\hat{a}_{ML}=\frac{\sum x_{t+1}x_{t}}{\sum x_t^2}$.

We again see the power of the ML device.
Could we have arrive to this estimator by intuiton alone? Hmmmm... maybe. 
See that $Cov[X_{t+1},X_t] = a \; Var[X_t] \Rightarrow a=\frac{Cov[X_{t+1},X_t]}{Var[X_t]}$.
So $a$ can also be derived using the moment matching method which is probably more intuitive.

\end{example}

\begin{example}[Linear Regression]

Estimate $\beta$ in $Y \sim \gauss{X\beta,\sigma^2 I}$, a $p$ dimensional random vector.
Recalling the multivariate Gaussian PDF:
$$
  p_{\mu,\Sigma}(y) = 
  (2 \pi)^{-n/2} |\Sigma|^{-1/2} \exp\left(
    -\frac{1}{2} (y-\mu)' \Sigma^{-1} (y-\mu)
  \right)
$$
So in the regression setup:
$$
  \lik{\beta}= 
  p_{\beta,\sigma^2}(y) = 
  (2 \pi)^{-n/2} |\sigma^2 I|^{-1/2} \exp\left(
    -\frac{1}{2 \sigma^2} \norm{y-X\beta}^2
  \right)
$$

\end{example}


\subsection{M-Estimation and Empirical Risk Minimization}
\label{sec:m_estimation}

M-Estimation, know as Empirical Risk Minimizaton (ERM) in the machine learning literature, is a very wide framework which stems from statistical desicion theory.
The underlying idea is that each realization of $X$ incurs some loss, and we seek to find a "policy", in this case a parameter, $\theta^*$ that minimizes the average loss.
In the econometric literature, we dot not incur a loss, but rather a utility, we thus seek a policy that maximizes the average utility.

Define a loss function $\loss{X;\theta}$, and a risk function, being the expected loss, $\risk{\theta}:=\expect{\loss{X;\theta}}$. Then 
\begin{align}
\label{eq:risk_min}
 \theta^*:= argmin_\theta\{\risk{\theta}\}.
\end{align}



As we do not know the distribution of $X$, we cannot solve 

\begin{example}[Squared loss]
Let $\loss{X;\theta}=\frac{1}{2}(X-\theta)^2$. Then 


\end{example}


\section{From Estimation to Learning}
\label{sec:learning}

\subsection{Empirical Risk Minimization (ERM) and Inductive Bias}

\subsection{Linear Regression (OLS)}

\subsection{Ridge Regression}

\subsection{Logistic Regression}

\subsection{LASSO}

\subsection{Linear SVM }

\subsection{Generalized Additive Models (GAMs)}

\subsection{Neural Nets (NNETs)}

\subsection{Classification and Regression Trees (CARTs)}





\end{document}