---
title: "Supervised Learning"
author: "Jonathan Rosenblatt"
date: "April 12, 2015"
output: html_document
  toc: true
---
In these examples, two data sets from the `ElemStatLearn` package: `spam` for categorical predictions, and `prostate` for continuous predictions.
In `spam` we will try to decide if a mail is spam or not. 
In `prostate` we will try to predict the size of a cancerous tumor.

```{r}
library(ElemStatLearn)
data("prostate")
data("spam")
```
You can now call `?prostate` and `?spam` to learn more about the variables in the data.

We also load some utility packages and functions that we will require down the road. 
```{r preamble}
library(magrittr) # for piping
library(dplyr) # for handeling data frames

l2 <- function(x) x^2 %>% sum %>% sqrt
l1 <- function(x) abs(x) %>% sum 
MSE <- function(x) x^2 %>% mean

missclassification <- function(tab) sum(tab[c(2,3)])/sum(tab)
```


# OLS

## OLS Regression

Starting with OLS regression, and a split train-test data set:
```{r OLS Regression}
prostate %>% names

prostate.train <- prostate %>% filter(train) %>% select(-train)
prostate.test <- prostate %>% filter(!train) %>% select(-train)
# now verify that your data looks as you would expect....

ols.1 <- lm(lcavol~. ,data = prostate.train)
# Train error:
MSE( predict(ols.1)- prostate.train$lcavol)
# Test error:
MSE( predict(ols.1, newdata = prostate.test)- prostate.test$lcavol)
```

Now using cross validation to estimate the prediciton error:
```{r Cross Validation}
folds <- 5
fold.assignment <- sample(1:5, nrow(prostate), replace = TRUE)
errors <- NULL

for (k in 1:folds){
  prostate.cross.train <- prostate[fold.assignment!=k,]
  prostate.cross.test <-  prostate[fold.assignment==k,] 
  .ols <- lm(lcavol~. ,data = prostate.cross.train)
  .predictions <- predict(.ols, newdata=prostate.cross.test)
  .errors <-  .predictions - prostate.cross.test$lcavol
  errors <- c(errors, .errors)
}

# Cross validated prediction error:
MSE(errors)
```

Also trying a bootstrap prediction error:
```{r Bootstrap}
B <- 20
n <- nrow(prostate)
errors <- NULL

prostate.boot.test <-  prostate 
for (b in 1:B){
  prostate.boot.train <- prostate[sample(1:n, replace = TRUE),]
  .ols <- lm(lcavol~. ,data = prostate.boot.train)
  .predictions <- predict(.ols, newdata=prostate.boot.test)
  .errors <-  .predictions - prostate.boot.test$lcavol
  errors <- c(errors, .errors)
}

# Bootstrapped prediction error:
MSE(errors)
```


### OLS Regression Model Selection 
Trying Bootstrapped, Cross Validated, and AIC.

AIC model selection: 
```{r OLS AIC}
step(ols.1, scope=model.scope, direction='backward', trace = TRUE)

ols.0 <- lm(lcavol~1 ,data = prostate.train)
model.scope <- list(upper=ols.1, lower=ols.0)
step(ols.0, scope=model.scope, direction='forward', trace = TRUE)
```


Cross Validated Model Selection.
```{r OLS CV}

```


Bootstrap model selection:
```{r OLS bootstrap}



```




## OLS Classification
```{r OLS Classification}
names(spam)
n <- nrow(spam)
spam.dummy <- spam %>% mutate(spam=as.numeric(spam=='spam'))

# Making train and test sets:
train.prop <- 0.66
train.ind <- c(TRUE,FALSE) %>% 
  sample(size = n, prob = c(train.prop,1-train.prop), replace=TRUE)
spam.train <- spam.dummy[train.ind,]
spam.test <- spam.dummy[!train.ind,]

ols.2 <- lm(spam~., data = spam.train)

# Train confusion matrix:
.predictions.train <- predict(ols.2) > 0.5
(confusion.train <- table(prediction=.predictions.train, truth=spam.train$spam))
missclassification(confusion.train)

# Test confusion matrix:
.predictions.test <- predict(ols.2, newdata = spam.test) > 0.5
(confusion.test <- table(prediction=.predictions.test, truth=spam.test$spam))
missclassification(confusion.test)
```



# Ridge Regression

```{r Ridge I}
library(ridge)

ridge.1 <- linearRidge(lcavol~. ,data = prostate.train)
# Note that if not specified, lambda is chosen automatically by linearRidge.

# Train error:
MSE( predict(ridge.1)- prostate.train$lcavol)
# Test error:
MSE( predict(ridge.1, newdata = prostate.test)- prostate.test$lcavol)
```

Another implementation, which also automatically chooses the tuning parameter $\lambda$:
```{r Ridge II}
library(glmnet)
y.train <- prostate.train$lcavol
X.train <- prostate.train %>% select(-lcavol) %>% as.matrix
ridge.2 <- glmnet(x=X.train, y=y.train, alpha = 0)

# Train error:
MSE( predict(ridge.2, newx =X.train)- y.train)

# Test error:
y.test <- prostate.test$lcavol 
X.test <- prostate.test %>% select(-lcavol) %>% as.matrix

MSE( predict(ridge.2, newx = X.test)- y.test)
```

__Note__:  `glmnet` is slightly picky: I could not have created `y.train` using `select()` because I need a vector and not a `data.frame`. Also, `as.matrix` is there as `glmnet` expects a `matrix` class `x` argument.




# LASSO Regression
```{r LASSO}
library(glmnet)
y.train <- prostate.train$lcavol
X.train <- prostate.train %>% select(-lcavol) %>% as.matrix
lasso.1 <- glmnet(x=X.train, y=y.train, alpha = 1)

# Train error:
MSE( predict(lasso.1, newx =X.train)- y.train)

# Test error:
y.test <- prostate.test$lcavol
X.test <- prostate.test %>% select(-lcavol) %>% as.matrix

MSE( predict(lasso.1, newx = X.test)- y.test)
```


# Logistic Regression For Classification
```{r Logistic Regression}
# Making train and test sets:
train.prop <- 0.66
train.ind <- c(TRUE,FALSE) %>%  sample(size = n, prob = c(train.prop,1-train.prop), replace=TRUE)
spam.train <- spam[train.ind,]
spam.test <- spam[!train.ind,]

logistic.1 <- glm(spam~., data = spam.train, family = binomial)
# numerical error. Probably due to too many predictors. 
# Maybe regularizing the logistic regressio with Ridge or LASSO will make things better?
```

In the next chunk, we do $l_2$ and $l_1$ regularized logistic regression.
Some techincal remarks are in order:

- `glmnet` is picky with its inputs. This has already been discussed in the context of the LASSO regression above.
- The `predict` function for `glmnet` objects returns a prediction (see below) for many candidate  regularization levels $\lambda$. We thus we `cv.glmnet` which does an automatic cross validated selection of the best regularization level. 
```{r Regularized Logistic Regression}
library(glmnet)
y.train <- spam.train$spam
X.train <- spam.train %>% select(-spam) %>% as.matrix
# Ridge Regularization with CV selection of regularization:
logistic.2 <- cv.glmnet(x=X.train, y=y.train, family = "binomial", alpha = 0)
# LASSO Regularization with CV selection of regularization:
logistic.3 <- cv.glmnet(x=X.train, y=y.train, family = "binomial", alpha = 1)


# Train confusion matrix:
.predictions.train <- predict(logistic.2, newx = X.train, type = 'class') 
(confusion.train <- table(prediction=.predictions.train, truth=spam.train$spam))
missclassification(confusion.train)

.predictions.train <- predict(logistic.3, newx = X.train, type = 'class') 
(confusion.train <- table(prediction=.predictions.train, truth=spam.train$spam))
missclassification(confusion.train)

# Test confusion matrix:
y.test <- spam.test$spam
X.test <- spam.test %>% select(-spam) %>% as.matrix


.predictions.test <- predict(logistic.2, newx = X.test, type='class') 
(confusion.test <- table(prediction=.predictions.test, truth=y.test))
missclassification(confusion.test)

.predictions.test <- predict(logistic.3, newx = X.test, type='class') 
(confusion.test <- table(prediction=.predictions.test, truth=y.test))
missclassification(confusion.test)
```




# SVM

## Classification
```{r SVM classification}
train.prop <- 0.66
train.ind <- c(TRUE,FALSE) %>%  sample(size = n, prob = c(train.prop,1-train.prop), replace=TRUE)
spam.train <- spam[train.ind,]
spam.test <- spam[!train.ind,]

library(e1071)
svm.1 <- svm(spam~., data = spam.train)

# Train confusion matrix:
.predictions.train <- predict(svm.1) 
(confusion.train <- table(prediction=.predictions.train, truth=spam.train$spam))
missclassification(confusion.train)

# Test confusion matrix:
.predictions.test <- predict(svm.1, newdata = spam.test) 
(confusion.test <- table(prediction=.predictions.test, truth=spam.test$spam))
missclassification(confusion.test)
```


## Regression
```{r SVM regression}
prostate.train <- prostate %>% filter(train) %>% select(-train)
prostate.test <- prostate %>% filter(!train) %>% select(-train)

svm.2 <- svm(lcavol~., data = prostate.train)

# Train error:
MSE( predict(svm.2)- prostate.train$lcavol)
# Test error:
MSE( predict(svm.2, newdata = prostate.test)- prostate.test$lcavol)
```




# GAM Regression
```{r GAM}
# install.packages('mgcv')
library(mgcv)
form.1 <- lcavol~ s(lweight)+ s(age)+s(lbph)+s(svi)+s(lcp)+s(gleason)+s(pgg45)+s(lpsa)
gam.1 <- gam(form.1, data = prostate.train)

sort(abs(coef(ridge.1)), decreasing = TRUE)
form.2 <- lcavol~  s(lweight)+ s(age)+s(lbph)+s(lcp)+s(pgg45)+s(lpsa)
gam.2 <- gam(form.2, data = prostate.train)

# Train error:
MSE( predict(gam.2)- prostate.train$lcavol)
# Test error:
MSE( predict(gam.2, newdata = prostate.test)- prostate.test$lcavol)
```


# Neural Net

## Regression
```{r NNET regression}

```


## Classification
```{r NNET Classification}

```


# CART

## Regression
```{r Tree regression}

```


## Classification



# Kernel Regression
```{r kernel}

```


# Stacking
```{r Stacking}

```


